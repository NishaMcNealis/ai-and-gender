---
layout: post
title:  Ethical Considerations
permalink: /ethical-considerations/
---

Let's dive into some of the biggest ethical concerns surrounding VA technology.

<figure>
    <figcaption>Hey Siri, what impact could virtual assistants have on human relationships?</figcaption>
    <audio class="audio-1" controls>
    <source src="{{site.baseurl}}/assets/audio/human_connection.mp3" type="audio/mpeg">    
    </audio>
    <div class="dropdown">
    <span>See Transcript</span>
        <div class="dropdown-content">
            <p>According to a 2018 study, users can be aware that AI assistants are not sentient and still implicitly view them as humanoid — people responded with signs of stress when asked to switch off a robot with a computerized voice that was begging them not to. The researchers wrote, “due to their social nature, people will rather make the mistake of treating something falsely as human than treating something falsely as non-human” These results are exacerbated when gender comes into play. Women are more often socialized to be loving, nurturing, and kind, while men are raised to be forceful, assertive, and competent. A 2021 meta-analysis of four studies found that female chatbots and robots are perceived as more sociable, less competent, and more human than their male counterparts. Unfortunately, tech companies have a vested interest in exploiting this phenomenon. Experiments have found that the personification of Alexa was associated with increased user satisfaction, even if the more human-like Alexa had more technological defects. 91.1% of reviews that personified Alexa were classified as “joyful” using sentiment analysis. The humanization of machines can keep users loyal to substandard products. It should come as no surprise that Amazon is currently working on building a more nuanced personality for Alexa and improving her conversational skills. </p>
        </div>
    </div>
</figure>

<figure>
    <figcaption>Ok Google, how will digital assistants contribute to the patriarchy?</figcaption>
    <audio class="audio-1" controls>
    <source src="{{site.baseurl}}/assets/audio/misogyny.mp3" type="audio/mpeg">    
    </audio>
</figure>

<figure>
    <figcaption>Alexa, how will marginalized groups be affected by VA technology?</figcaption>
    <audio class="audio-1" controls>
    <source src="{{site.baseurl}}/assets/audio/intersectionality.mp3" type="audio/mpeg">    
    </audio>
</figure>

<a class="github-button" href="https://nishamcnealis.github.io/ai-and-gender/solutions/" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Next: Solutions">Next</a>